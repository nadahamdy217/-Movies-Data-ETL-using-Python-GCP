{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from google.cloud import storage\n",
    "\n",
    "# Creating an Environmental Variable for the service key configuration\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'D:\\DEPI Data Engineer\\0_projects\\ETL MOVIES\\ServiceKey_GoogleCloud.json'\n",
    "\n",
    "# Creating a storage client\n",
    "storage_client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SCOPE', '_SET_PROJECT', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_base_connection', '_batch_stack', '_bucket_arg_to_bucket', '_client_cert_source', '_connection', '_credentials', '_delete_resource', '_determine_default', '_extra_headers', '_get_resource', '_http', '_http_internal', '_initial_client_info', '_initial_client_options', '_is_emulator_set', '_list_resource', '_patch_resource', '_pop_batch', '_post_resource', '_push_batch', '_put_resource', '_universe_domain', 'api_endpoint', 'batch', 'bucket', 'close', 'create_anonymous_client', 'create_bucket', 'create_hmac_key', 'current_batch', 'download_blob_to_file', 'from_service_account_info', 'from_service_account_json', 'generate_signed_post_policy_v4', 'get_bucket', 'get_hmac_key_metadata', 'get_service_account_email', 'list_blobs', 'list_buckets', 'list_hmac_keys', 'lookup_bucket', 'project', 'universe_domain']\n"
     ]
    }
   ],
   "source": [
    "# List the class methods\n",
    "print(dir(storage_client))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully!\n",
      "File unzipped successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# URL of the file to download\n",
    "url = \"https://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "\n",
    "# Path where the file will be saved\n",
    "zip_path = r\"D:\\DEPI Data Engineer\\0_projects\\ETL MOVIES\\ml-100k.zip\"\n",
    "# Path where the contents will be extracted\n",
    "extract_to = r\"D:\\DEPI Data Engineer\\0_projects\\ETL MOVIES\"\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url, stream=True)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Save the file\n",
    "    with open(zip_path, \"wb\") as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            file.write(chunk)\n",
    "    print(\"File downloaded successfully!\")\n",
    "\n",
    "    # Unzip the file\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    print(\"File unzipped successfully!\")\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to download file. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_data.py\n",
    "\n",
    "import pandas as pd\n",
    "from os import read\n",
    "import numpy as np\n",
    "\n",
    "# Create a DatFrame for Movie Ratings\n",
    "ratings = pd.read_csv('ml-100k/u.data', delimiter='\\t', header=None, names=['user_id','item_id', 'rating' ,'timestamp'])\n",
    "\n",
    "\n",
    "# Create a DataFrame for Movie Names\n",
    "with open('ml-100k/u.item', 'r', encoding=\"ISO-8859-1\") as read_file:\n",
    "    \n",
    "    counter = 0\n",
    "    movies_df = pd.DataFrame(columns=['item_id', 'movie_name', 'release_timestamp'])\n",
    "\n",
    "    # Iterate thorugh the lines in the file\n",
    "    for line in read_file:\n",
    "\n",
    "        # From each line extract the first three values\n",
    "        fields = line.split('|')\n",
    "        item_id, movie_name, release_timestamp = fields[0], fields[1], fields[2]\n",
    "        movie_name = movie_name[0:len(movie_name) - len(' (1234)')]\n",
    "\n",
    "        # Aggerate line data\n",
    "        line_data = [int(item_id), str(movie_name), release_timestamp]\n",
    "\n",
    "        # Create a temp dataframe and append it to movies_df\n",
    "        temp_df = pd.DataFrame(data=[line_data], columns=['item_id', 'movie_name', 'release_timestamp'])\n",
    "        movies_df = pd.concat([temp_df, movies_df], ignore_index=True)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    # Sort Values by item id\n",
    "    movies_df.sort_values(by='item_id', ascending=True, inplace=True)\n",
    "\n",
    "# Close file\n",
    "read_file.close()\n",
    "\n",
    "# Export to CSV\n",
    "ratings.to_csv('ratings.csv', index=False)\n",
    "movies_df.to_csv('movies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
